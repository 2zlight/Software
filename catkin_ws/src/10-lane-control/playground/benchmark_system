#!/usr/bin/python
import sys
import rospy
import rosbag
import argparse
import cv2
import numpy as np
import duckietown_utils as dtu

from anti_instagram.AntiInstagram import AntiInstagram
from ground_projection.GroundProjection import GroundProjection
from lane_filter.lane_filter import *
from os.path import isfile
from os import (makedirs, environ, path)
from sensor_msgs.msg import CameraInfo
from geometry_msgs.msg import Point
from collections import OrderedDict
from ruamel.yaml.comments import CommentedMap
from easy_algo.algo_db import get_easy_algo_db
from duckietown_msgs.msg import (Segment, SegmentList)
from line_detector.visual_state_fancy_display import vs_fancy_display
from line_detector2.run_programmatically import FakeContext

def load_filter_config(filename=''):
    # Load lane_filter config
    if not isfile(filename):
        filename = dtu.path_utils.get_ros_package_path('duckietown') + '/config/baseline/lane_filter/lane_filter_node/default.yaml'
    filter_config = dtu.yaml_wrap.yaml_load_file(filename)
    configuration = []
    configuration.append(filter_config['filter'][0])
    configuration.append(filter_config['filter'][1])
    dtu.logger.info("Loaded lane_filter configuration")
    return configuration

def load_camera_info(robot):
    # Load camera information
    filename = (environ['DUCKIEFLEET_ROOT'] + "/calibrations/camera_intrinsic/" + robot + ".yaml")
    if not isfile(filename):
        logger.warn("no intrinsic calibration parameters for {}, trying default".format(robot))
        filename = (environ['DUCKIEFLEET_ROOT'] + "/calibrations/camera_intrinsic/default.yaml")
        if not isfile(filename):
            logger.error("can't find default either, something's wrong")
    calib_data = dtu.yaml_wrap.yaml_load_file(filename)
    cam_info = CameraInfo()
    cam_info.width = calib_data['image_width']
    cam_info.height = calib_data['image_height']
    cam_info.K = calib_data['camera_matrix']['data']
    cam_info.D = calib_data['distortion_coefficients']['data']
    cam_info.R = calib_data['rectification_matrix']['data']
    cam_info.P = calib_data['projection_matrix']['data']
    cam_info.distortion_model = calib_data['distortion_model']
    dtu.logger.info("Loaded camera calibration parameters for {} from {}".format(robot, path.basename(filename)))
    return cam_info

# Parse input arguments
parser = argparse.ArgumentParser(description='Read images from a given bag \
    and parse them through the image processing pipeline \
    to determine performance of the pose_estimator and lane_controller')
# parser.add_argument('rosbag', type=str, help='Input rosbag file')
parser.add_argument('imgIn', type=str, help='Input image file')
parser.add_argument('output', type=str, help='Output folder where logs are being stored')

args = parser.parse_args()
# rosbagIN = args.rosbag
imgIn = args.imgIn
output = args.output

# Perform file check
if not isfile(imgIn):
    print('The file "%s" does not exist' % imgIn)
    exit(2)

# Check image integrity
input = None
try:
    input = cv2.imread(imgIn)
except:
    print('The file "%s" cannot be decoded' % file)
    exit(3)
if input is None:
    exit(3)

# Create missing folders
try:
    makedirs(output)
except:
    pass

# Initialize variables
robot = 'yaf'
detector = 'baseline'
preparer = 'prep_200_100'
context = FakeContext()

algo_db = get_easy_algo_db()
line_detector = algo_db.create_instance('line_detector', detector)
image_preparer = algo_db.create_instance('image_prep', preparer)

# Instantiate needed classes
ai = AntiInstagram()
dtu.logger.info('Initialized instance of AntiInstagram')
ai.calculateTransform(input)

gp = GroundProjection(robot)
dtu.logger.info('Initialized instance of GroundProjection')
ci = CameraInfo()
ci = load_camera_info(robot)
# print(ci)
gp.initialize_pinhole_camera_model(ci)
# dtu.logger.info('Initialized pinhole camera model for %s' % robot)

lf_config = load_filter_config()
assert isinstance(lf_config, list) and len(lf_config) == 2, lf_config
lf = None
lf = dtu.instantiate_utils.instantiate(lf_config[0], lf_config[1])
dtu.logger.info('Initialized instance of %s' % str(lf_config[0]))

# # iterate over all possible line_detectors
# available = algo_db.query('line_detector', '*')
# print('Available line_detector interfaces:')
# for name in available:
#     print(name)

# # iterate over all possible image_preps
# available = algo_db.query('image_prep', '*')
# print('Available image_prep interfaces:')
# for name in available:
#     print(name)

# # Perform file check
# from os.path import isfile
# if not isfile(rosbagIN):
#     print('The file "%s" does not exist' % rosbagIN)
#     exit(2)

# # Instantiate rosbag Object
# bag = rosbag.Bag(rosbagIN)

# # Loop through images
# print('\tCreating thumbnails for rosbag: "%s"' % rosbagIN)
# messages = list(bag.read_messages(topic))
# for i in range(len(messages)):

#     img = dtu.rgb_from_ros(messages[i][1])
#     dtu.write_image_as_jpg(img, '%s/%05d.jpg' % (output, i))

# bag.close()

dtu.logger.info("Running image pipeline with %s line_detector and %s" % (detector, preparer))

# Transform image
input_transformed = ai.applyTransform(input)
input_transformed = np.clip(input_transformed, 0, 255).astype(np.uint8)

# Undistort image
# input_rectified = rectify(input_transformed, ci.K, ci.D, ci.R, ci.P, ci.height, ci.width)
input_rectified = gp.rectify(input_transformed)

# Get SegmentList from rectified image
dtu.logger.info('Receiving SegmentList')
segmentList = SegmentList()
segmentList_transformed = SegmentList()
segmentList = image_preparer.process(context, input_rectified, line_detector, transform=None)
print('Total amount of segments: %i' % np.size(segmentList.segments))
segmentList_transformed.header = segmentList.header

# Get ground truth of segmentList
for received_segment in segmentList.segments:
    new_segment = Segment()
    new_segment.points[0] = gp.vector2ground(received_segment.pixels_normalized[0])
    new_segment.points[1] = gp.vector2ground(received_segment.pixels_normalized[1])
    new_segment.color = received_segment.color
    # TODO what about normal and points
    segmentList_transformed.segments.append(new_segment)

# Add green middle line
# new_segment = Segment()
# point = Point()
# point.x = 0
# point.y = 0
# point.z = 0
# new_segment.pixels_normalized[0] = gp.ground2vector(point)
# point.x = 0.2
# new_segment.pixels_normalized[1] = gp.ground2vector(point)
# new_segment.color = 3
# segmentList.segments.append(new_segment)

# Get Estimation
dtu.logger.info('Receiving pose estimation')
lf.update(segmentList_transformed.segments)

result = vs_fancy_display(input_rectified, segmentList)
# print(segmentList.segments)

[d_max, phi_max] = lf.getEstimate()
max_val = lf.getMax()
in_lane = max_val > lf.min_max 

print('\ndistance:\t %f cm' % (d_max*100))
print('angle:\t\t %f deg' % phi_max)
print('in_lane:\t %s' % in_lane)

# Show results
cv2.imshow("Input image", input)
cv2.imshow("Resulting image", input_transformed)
cv2.imshow("Rectified image", input_rectified)
cv2.imshow("Rectified with segmets", result)

cv2.waitKey(0)