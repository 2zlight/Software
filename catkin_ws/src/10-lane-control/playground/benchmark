#!/usr/bin/python
import sys
import time
import rosbag
import argparse
import cv2
import os
import numpy as np
import matplotlib.ticker as ticker
import duckietown_utils as dtu

from anti_instagram.AntiInstagram import AntiInstagram
from ground_projection.GroundProjection import GroundProjection
from lane_filter.lane_filter import *
from matplotlib import pyplot as plt
from os.path import (isfile, dirname, basename)
from os import (makedirs, environ, path)
from sensor_msgs.msg import CameraInfo
from easy_algo.algo_db import get_easy_algo_db
from duckietown_msgs.msg import (Segment, SegmentList)
from line_detector.visual_state_fancy_display import vs_fancy_display
from line_detector2.run_programmatically import FakeContext

import warnings
warnings.filterwarnings("ignore")


class Benchmark():
    def __init__(self):
        self.path = None
        self.save_images = False
        self.preparer = 'prep_200_70'
        self.fast = True

    def run(self):
        pathArray = []

        # Perform file check
        if not os.path.isfile(self.path):
            if os.path.isdir(self.path):
                for file in os.listdir(self.path):
                    if file.endswith(".bag"):
                        pathArray.append(os.path.join(self.path, file))
                print('Input rosbags:')
                for file in (pathArray):
                    print(file)
            elif not os.path.isdir(self.path):
                print('The file "%s" does not exist' % self.path)
                exit(2)
        else:
            pathArray.append(self.path)

        for file in (pathArray):
            print('\nNow Processing: %s' % file)
            self.rosbagPath = file
            self.rosbagIN = basename(self.rosbagPath)
            self.output = ('%s/%s/%s' % (dirname(self.rosbagPath), args.output, self.rosbagIN[:-4]))
            # Create missing folders
            try:
                makedirs(self.output)
            except:
                pass

            self.processBag()

    def load_filter_config(self, filename=''):
        # Load lane_filter config
        if not isfile(filename):
            filename = dtu.path_utils.get_ros_package_path('duckietown') + '/config/baseline/lane_filter/lane_filter_node/default.yaml'
        filter_config = dtu.yaml_wrap.yaml_load_file(filename)
        configuration = []
        configuration.append(filter_config['filter'][0])
        configuration.append(filter_config['filter'][1])
        dtu.logger.info("Loaded lane_filter configuration")
        return configuration

    def load_camera_info(self, robot):
        # Load camera information
        filename = (environ['DUCKIEFLEET_ROOT'] + "/calibrations/camera_intrinsic/" + robot + ".yaml")
        if not isfile(filename):
            dtu.logger.warn("no intrinsic calibration parameters for {}, trying default".format(robot))
            filename = (environ['DUCKIEFLEET_ROOT'] + "/calibrations/camera_intrinsic/default.yaml")
            if not isfile(filename):
                logger.error("can't find default either, something's wrong")
        calib_data = dtu.yaml_wrap.yaml_load_file(filename)
        cam_info = CameraInfo()
        cam_info.width = calib_data['image_width']
        cam_info.height = calib_data['image_height']
        cam_info.K = calib_data['camera_matrix']['data']
        cam_info.D = calib_data['distortion_coefficients']['data']
        cam_info.R = calib_data['rectification_matrix']['data']
        cam_info.P = calib_data['projection_matrix']['data']
        cam_info.distortion_model = calib_data['distortion_model']
        dtu.logger.info("Loaded camera calibration parameters for {} from {}".format(robot, path.basename(filename)))
        return cam_info

    def process_image(self, imgArray, i):
        img = dtu.rgb_from_ros(imgArray[0])
        input = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Transform image
        if (i == 0):
            self.ai.calculateTransform(input)
        input_transformed = self.ai.applyTransform(input)
        input_transformed = np.clip(input_transformed, 0, 255).astype(np.uint8)

        # Undistort image
        input_rectified = self.gp.rectify(input_transformed)

        # Get SegmentList from rectified image
        segmentList = SegmentList()
        segmentList_transformed = SegmentList()
        segmentList = self.image_preparer.process(self.context, input_rectified, self.line_detector, transform=None)
        segmentList_transformed.header = segmentList.header

        # Get ground truth of segmentList
        for received_segment in segmentList.segments:
            new_segment = Segment()
            new_segment.points[0] = self.gp.vector2ground(received_segment.pixels_normalized[0])
            new_segment.points[1] = self.gp.vector2ground(received_segment.pixels_normalized[1])
            new_segment.color = received_segment.color
            # TODO what about normal and points
            segmentList_transformed.segments.append(new_segment)

        # Get Estimation
        self.lf.update(segmentList_transformed.segments)

        result = vs_fancy_display(input_rectified, segmentList)
        [d_max, phi_max] = self.lf.getEstimate()
        max_val = self.lf.getMax()
        in_lane = max_val > self.lf.min_max 

        self.dComputedArray.append([d_max, imgArray[1]])
        self.phiComputedArray.append([phi_max, imgArray[1]])
        return result

    def create_Plots(self, dArray, phiArray, dComputedArray, phiComputedArray, segmentArray):
        if segmentArray.any():
            fig, ax = plt.subplots(3, sharex=True)
        else:
            fig, ax = plt.subplots(2, sharex=True)
        ax[0].plot(dArray[:,1]-self.startTime, dArray[:,0]*100, color="blue", label=r'$d_{est}$')
        ax[1].plot(phiArray[:,1]-self.startTime, phiArray[:,0], color="red", label=r'$phi_{est}$')
        if dComputedArray.any():
            ax[0].plot(dComputedArray[:,1]-self.startTime, dComputedArray[:,0]*100, linestyle=':', color="blue", label=r'$d_{comp}$')
            ax[1].plot(phiComputedArray[:,1]-self.startTime, phiComputedArray[:,0], linestyle=':', color="red", label=r'$phi_{comp}$')
        ax[0].set_title('Performance evaluation of %s' % self.rosbagIN[:-4])
        ax[0].set_ylim(-25, 25)
        ax[0].yaxis.set_major_locator(ticker.MaxNLocator(10))
        ax[0].set_ylabel('distance [cm]')
        ax[0].set_xlim(left=0)
        ax[0].xaxis.set_major_locator(ticker.MaxNLocator(10))
        ax[0].xaxis.set_minor_locator(ticker.MaxNLocator(50))
        ax[0].legend(loc='upper right')
        ax[0].grid(color='grey', linestyle=':', linewidth=1)
        ax[0].grid(which='minor', color='grey', linestyle=':', alpha=0.5, linewidth=1)
        ax[0].text(0.99, 0.14, "mean: %s\nmedian: %s" % (round(self.d_mean*100,3), round(self.d_median*100,3)), ha="right", 
            va="center", transform=ax[0].transAxes,bbox={'boxstyle': 'square', 'fc': 'white', 'ec': 'black'})
        ax[1].set_ylim(-2.5, 2.5)
        ax[1].set_ylabel('tracking angle [deg]')
        ax[1].yaxis.set_major_locator(ticker.MaxNLocator(10))
        ax[1].legend(loc='upper right')
        ax[1].grid(color='grey', linestyle=':', linewidth=1)
        ax[1].grid(which='minor', color='grey', linestyle=':', alpha=0.5, linewidth=1)
        ax[1].text(0.99, 0.14, "mean: %s\nmedian: %s" % (round(self.phi_mean,3), round(self.phi_median,3)), ha="right", 
            va="center", transform=ax[1].transAxes,bbox={'boxstyle': 'square', 'fc': 'white', 'ec': 'black'})

        if segmentArray.any():
            ax[2].plot(segmentArray[:,1]-self.startTime, segmentArray[:,0], color="orange", label=r'$n_{segment}$')
            ax[2].set_ylim(10, 110)
            ax[2].set_ylabel('amount of segments')
            ax[2].set_xlabel('time [sec]')
            ax[2].yaxis.set_major_locator(ticker.MaxNLocator(10))
            ax[2].legend(loc='upper right')
            ax[2].grid(color='grey', linestyle=':', linewidth=1)
            ax[2].grid(which='minor', color='grey', linestyle=':', alpha=0.5, linewidth=1)
            ax[2].text(0.99, 0.14, "mean: %s\nmedian: %s" % (round(np.mean(segmentArray[:,0]),3), round(np.median(segmentArray[:,0]),3)), ha="right", 
                va="center", transform=ax[2].transAxes,bbox={'boxstyle': 'square', 'fc': 'white', 'ec': 'black'})
        fig.set_size_inches(20, 10)
        fig.savefig('%s/%s.png' % (self.output, self.rosbagIN[:-4]), dpi=300, bbox_inches='tight')
        # plt.show()

    def write_Logs(self, dArray, phiArray, segmentArray, SegmentProcessTime):
        logFile = open(('%s/%s.txt' % (self.output, self.rosbagIN[:-4])), 'w')
        logFile.write('Benchmark results for %s\n' % self.rosbagIN[:-4])
        logFile.write('\tdist min:\t%s\n' % round(self.d_min, 3))
        logFile.write('\tdist max:\t%s\n' % round(self.d_max, 3))
        logFile.write('\tdist mean:\t%s\n' % round(self.d_mean, 3))
        logFile.write('\tdist med:\t%s\n' % round(self.d_median, 3))
        logFile.write('\tdist var:\t%s\n' % round(self.d_var, 3))

        logFile.write('\tphi min:\t%s\n' % round(self.phi_min, 3))
        logFile.write('\tphi max:\t%s\n' % round(self.phi_max, 3))
        logFile.write('\tphi mean:\t%s\n' % round(self.phi_mean, 3))
        logFile.write('\tphi med:\t%s\n' % round(self.phi_median, 3))
        logFile.write('\tphi var:\t%s\n' % round(self.phi_var, 3))

        if segmentArray.any():
            logFile.write('\nImage segments statistics:')
            logFile.write('\tAverage amount of segments:\t%s\n' % round(np.mean(segmentArray[:,0]), 3))
            logFile.write('\tMedian amount of segments:\t%s\n' % round(np.median(segmentArray[:,0]), 3))
            logFile.write('\tAverage processing time per frame (on duckiebot):\t%s\n' % round(SegmentProcessTime, 3))

        logFile.write('\nRosbag processing time: %f\n' % (self.toc - self.tic))
        logFile.write('\tAverage processing time per frame: %f\n' % ((self.toc - self.tic) / len(dArray)))
        logFile.write('\tImage preparer used on computer: %s\n' % self.preparer)

        logFile = open(('%s/%s.csv' % (self.output, self.rosbagIN[:-4])), 'w')
        logFile.write('Distance; Angle:\n')
        if segmentArray.any():
            for d, phi, seg in zip(dArray, phiArray, segmentArray[:, 0]):
                logFile.write('%f; %f; %f\n' % (d, phi, seg))
        else:
            for d, phi, in zip(dArray, phiArray):
                logFile.write('%f; %f\n' % (d, phi))

    def getMessages(self, messages):
        result = []
        for i in range(len(messages)):
            result.append([messages[i][1], messages[i][2].to_sec()])
        return np.asarray(result)

    def processBag(self):
        # Instantiate rosbag Object
        bag = rosbag.Bag(self.rosbagPath)

        # Initialize variables
        robot = dtu.bag_info.which_robot(bag)
        # topic = ('/' + robot + '/camera_node/image/compressed')
        self.detector = 'baseline'
        self.context = FakeContext()

        # Loop through images
        print('Reading data from: "%s"' % self.rosbagIN)
        print('Robot name: %s' % robot)

        dArray = []
        phiArray = []
        self.dComputedArray = []
        self.phiComputedArray = []
        lanePoseArray = []
        ImageArray = []
        # beliefImgArray = []
        SegmentArray = []
        segmentArray = []
        SegmentArray = np.asarray(SegmentArray)
        segmentArray = np.asarray(segmentArray)
        SegmentProcessTime = 0

        self.tic = time.time()
        topics = bag.get_type_and_topic_info().topics
        for topic in topics:
            messages = list(bag.read_messages(topic))
            print('Reading %d\t messages of: %s' % (len(messages), topic))
            if 'line_detector_node/segment_list' in topic:
                SegmentArray = self.getMessages(messages)
            if 'lane_filter_node/lane_pose' in topic:
                lanePoseArray = self.getMessages(messages)
            # if 'lane_filter_node/belief_img' in topic:
            #     beliefImgArray = getMessages(messages)
            if 'image/compressed' in topic:
                ImageArray = self.getMessages(messages)
        bag.close()

        self.startTime = ImageArray[0,1]

        if SegmentArray.any():
            nSegmentLists = len(SegmentArray)
            segmentArray = []

            for i in range(len(SegmentArray)):
                segmentArray.append([len(SegmentArray[i,0].segments), SegmentArray[i,1]])

            # segment_mean = np.mean(segmentArray)
            SegmentProcessTime = (SegmentArray[-1][1] - SegmentArray[0][1]) / nSegmentLists

            for i in range(len(lanePoseArray)):
                dArray.append([lanePoseArray[i][0].d, lanePoseArray[i][1]])
                phiArray.append([lanePoseArray[i][0].phi, lanePoseArray[i][1]])

            dArray = np.asarray(dArray)
            phiArray = np.asarray(phiArray)

        else:
            self.fast = 'False'

        if not dArray.any():
            self.fast = 'False'

        dComputedArray = []
        phiComputedArray = []

        if self.fast == 'False':
            # Initialize variables
            algo_db = get_easy_algo_db()
            self.line_detector = algo_db.create_instance('line_detector', self.detector)
            self.image_preparer = algo_db.create_instance('image_prep', self.preparer)

            # Instantiate needed classes
            self.ai = AntiInstagram()
            dtu.logger.info('Initialized instance of AntiInstagram')

            self.gp = GroundProjection(robot)
            dtu.logger.info('Initialized instance of GroundProjection')
            self.ci = CameraInfo()
            self.ci = self.load_camera_info(robot)
            self.gp.initialize_pinhole_camera_model(self.ci)
            
            lf_config = self.load_filter_config()
            assert isinstance(lf_config, list) and len(lf_config) == 2, lf_config
            self.lf = None
            self.lf = dtu.instantiate_utils.instantiate(lf_config[0], lf_config[1])
            dtu.logger.info('Initialized instance of %s' % str(lf_config[0]))
            dtu.logger.info("Running image pipeline with %s line_detector and %s" % (self.detector, self.preparer))

            for i in range(len(ImageArray)):
                progress = float(i)/len(ImageArray)*100
                sys.stdout.write('\r[ %i%% ] Processing frames... ' % int(progress))
                sys.stdout.flush();
                result = self.process_image(ImageArray[i], i)
                if (self.save_images == True):
                    dtu.write_image_as_jpg(result, '%s/%05d.jpg' % (self.output, i))

            dComputedArray = np.asarray(self.dComputedArray)
            phiComputedArray = np.asarray(self.phiComputedArray)

        if not SegmentArray.any() or not dArray.any():
            dArray = dComputedArray
            phiArray = phiComputedArray

        self.d_min = np.min(dArray[:, 0])
        self.d_max = np.max(dArray[:, 0])
        self.d_mean = np.mean(dArray[:, 0])
        self.d_median = np.median(dArray[:, 0])
        self.d_var = np.var(dArray[:, 0])

        self.phi_min = np.min(phiArray[:, 0])
        self.phi_max = np.max(phiArray[:, 0])
        self.phi_mean = np.mean(phiArray[:, 0])
        self.phi_median = np.median(phiArray[:, 0])
        self.phi_var = np.var(phiArray[:, 0])

        print('\nDone')
        self.toc = time.time()
        print('Time Elapsed: %f' % (self.toc - self.tic))

        self.create_Plots(dArray, phiArray, np.asarray(dComputedArray), np.asarray(phiComputedArray), np.asarray(segmentArray))
        self.write_Logs(dArray[:, 0], phiArray[:, 0], np.asarray(segmentArray), SegmentProcessTime)

if __name__ == '__main__':
    # Create new Benchmark Instance
    bm = Benchmark()

    # Parse input arguments
    parser = argparse.ArgumentParser(description='Read images from a given bag \
        and parse them through the image processing pipeline \
        to determine performance of the pose_estimator and lane_controller')
    parser.add_argument('rosbag', type=str, help='Input rosbag file')
    parser.add_argument('--output', type=str, help='Output folder where logs are being stored', default="output", required=False)
    parser.add_argument('--save_images', help='If to save the processed images from the rosbag', default=False, required=False)
    parser.add_argument('--preparer', help='Lane filter configuration to use', default='prep_200_70', required=False)
    parser.add_argument('--fast', help='Only readout rosbag data without computing image segments', default=True, required=False)

    args = parser.parse_args()
    bm.path = args.rosbag
    bm.save_images = args.save_images
    bm.preparer = args.preparer
    bm.fast = args.fast

    bm.run()